{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e52c246",
   "metadata": {},
   "source": [
    "# TrOCR Fine-tuning for Handwritten Prescription Recognition\n",
    "\n",
    "This notebook demonstrates how to fine-tune Microsoft's TrOCR (Transformer-based Optical Character Recognition) model specifically for reading handwritten medical prescriptions.\n",
    "\n",
    "## Overview:\n",
    "- **Goal**: Extract drug names and dosage information from handwritten prescription images\n",
    "- **Model**: Microsoft TrOCR (pre-trained on handwritten text)\n",
    "- **Dataset**: ~100 handwritten prescription images with annotations\n",
    "- **Output**: Structured text that can be fed to the Zaura Health drug interaction model\n",
    "\n",
    "## Pipeline:\n",
    "1. **Data Preparation**: Organize prescription images and create annotations\n",
    "2. **Model Setup**: Load pre-trained TrOCR model\n",
    "3. **Fine-tuning**: Train on prescription-specific vocabulary and layout\n",
    "4. **Evaluation**: Test accuracy on prescription text extraction\n",
    "5. **Integration**: Create API for Zaura Health website\n",
    "\n",
    "## Requirements:\n",
    "- Prescription images in common formats (JPG, PNG)\n",
    "- Ground truth transcriptions for training\n",
    "- GPU recommended for training (CPU supported but slower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1201e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers[torch] datasets pillow torch torchvision accelerate evaluate nltk rouge-score\n",
    "!pip install opencv-python matplotlib seaborn tqdm\n",
    "!pip install --upgrade huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d631ca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import re\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Transformers and ML libraries\n",
    "from transformers import (\n",
    "    TrOCRProcessor, \n",
    "    VisionEncoderDecoderModel,\n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    default_data_collator\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from torch.utils.data import DataLoader\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c323313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for the fine-tuning process\n",
    "class TrOCRConfig:\n",
    "    # Paths\n",
    "    BASE_DIR = Path.cwd()\n",
    "    DATA_DIR = BASE_DIR / \"prescription_data\"\n",
    "    IMAGES_DIR = DATA_DIR / \"images\"\n",
    "    ANNOTATIONS_FILE = DATA_DIR / \"annotations.json\"\n",
    "    OUTPUT_DIR = BASE_DIR / \"trocr_prescription_model\"\n",
    "    \n",
    "    # Model settings\n",
    "    MODEL_NAME = \"microsoft/trocr-base-handwritten\"  # Pre-trained on handwritten text\n",
    "    MAX_TARGET_LENGTH = 256  # Maximum length of prescription text\n",
    "    \n",
    "    # Training parameters\n",
    "    BATCH_SIZE = 4  # Adjust based on GPU memory\n",
    "    LEARNING_RATE = 5e-5\n",
    "    NUM_EPOCHS = 10\n",
    "    WARMUP_STEPS = 100\n",
    "    EVAL_STEPS = 50\n",
    "    SAVE_STEPS = 100\n",
    "    \n",
    "    # Data split\n",
    "    TRAIN_SPLIT = 0.8\n",
    "    VAL_SPLIT = 0.1\n",
    "    TEST_SPLIT = 0.1\n",
    "\n",
    "config = TrOCRConfig()\n",
    "\n",
    "# Create directories if they don't exist\n",
    "config.DATA_DIR.mkdir(exist_ok=True)\n",
    "config.IMAGES_DIR.mkdir(exist_ok=True)\n",
    "config.OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Configuration setup complete!\")\n",
    "print(f\"Data directory: {config.DATA_DIR}\")\n",
    "print(f\"Model will be saved to: {config.OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34da144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation utilities\n",
    "class PrescriptionDatasetCreator:\n",
    "    \"\"\"Helper class to create and manage prescription dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, images_dir: Path, annotations_file: Path):\n",
    "        self.images_dir = images_dir\n",
    "        self.annotations_file = annotations_file\n",
    "    \n",
    "    def create_sample_annotations(self):\n",
    "        \"\"\"Create a sample annotations file structure for reference\"\"\"\n",
    "        sample_annotations = {\n",
    "            \"dataset_info\": {\n",
    "                \"description\": \"Handwritten prescription OCR dataset\",\n",
    "                \"version\": \"1.0\",\n",
    "                \"total_images\": 100\n",
    "            },\n",
    "            \"annotations\": [\n",
    "                {\n",
    "                    \"image_id\": \"prescription_001.jpg\",\n",
    "                    \"text\": \"Aspirin 100mg twice daily\\nMetformin 500mg once daily\\nLisinopril 10mg once daily\",\n",
    "                    \"drugs_extracted\": [\"Aspirin\", \"Metformin\", \"Lisinopril\"],\n",
    "                    \"dosages\": [\"100mg\", \"500mg\", \"10mg\"],\n",
    "                    \"frequencies\": [\"twice daily\", \"once daily\", \"once daily\"]\n",
    "                },\n",
    "                {\n",
    "                    \"image_id\": \"prescription_002.jpg\",\n",
    "                    \"text\": \"Amoxicillin 250mg three times daily\\nIbuprofen 400mg as needed\",\n",
    "                    \"drugs_extracted\": [\"Amoxicillin\", \"Ibuprofen\"],\n",
    "                    \"dosages\": [\"250mg\", \"400mg\"],\n",
    "                    \"frequencies\": [\"three times daily\", \"as needed\"]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        with open(self.annotations_file, 'w') as f:\n",
    "            json.dump(sample_annotations, f, indent=2)\n",
    "        \n",
    "        print(f\"Sample annotations created at: {self.annotations_file}\")\n",
    "        print(\"Please replace with your actual annotations!\")\n",
    "    \n",
    "    def load_annotations(self) -> Dict:\n",
    "        \"\"\"Load annotations from JSON file\"\"\"\n",
    "        if not self.annotations_file.exists():\n",
    "            print(\"Annotations file not found. Creating sample structure...\")\n",
    "            self.create_sample_annotations()\n",
    "            return None\n",
    "        \n",
    "        with open(self.annotations_file, 'r') as f:\n",
    "            annotations = json.load(f)\n",
    "        \n",
    "        print(f\"Loaded {len(annotations['annotations'])} annotations\")\n",
    "        return annotations\n",
    "    \n",
    "    def validate_dataset(self) -> bool:\n",
    "        \"\"\"Validate that images and annotations match\"\"\"\n",
    "        annotations = self.load_annotations()\n",
    "        if not annotations:\n",
    "            return False\n",
    "        \n",
    "        # Check if all annotated images exist\n",
    "        missing_images = []\n",
    "        for ann in annotations['annotations']:\n",
    "            image_path = self.images_dir / ann['image_id']\n",
    "            if not image_path.exists():\n",
    "                missing_images.append(ann['image_id'])\n",
    "        \n",
    "        if missing_images:\n",
    "            print(f\"Warning: Missing images: {missing_images}\")\n",
    "            return False\n",
    "        \n",
    "        print(\"âœ“ Dataset validation passed\")\n",
    "        return True\n",
    "    \n",
    "    def get_dataset_stats(self) -> Dict:\n",
    "        \"\"\"Get statistics about the dataset\"\"\"\n",
    "        annotations = self.load_annotations()\n",
    "        if not annotations:\n",
    "            return {}\n",
    "        \n",
    "        texts = [ann['text'] for ann in annotations['annotations']]\n",
    "        text_lengths = [len(text) for text in texts]\n",
    "        \n",
    "        # Extract all drugs mentioned\n",
    "        all_drugs = []\n",
    "        for ann in annotations['annotations']:\n",
    "            if 'drugs_extracted' in ann:\n",
    "                all_drugs.extend(ann['drugs_extracted'])\n",
    "        \n",
    "        stats = {\n",
    "            'total_prescriptions': len(annotations['annotations']),\n",
    "            'avg_text_length': np.mean(text_lengths),\n",
    "            'max_text_length': max(text_lengths),\n",
    "            'min_text_length': min(text_lengths),\n",
    "            'unique_drugs': len(set(all_drugs)),\n",
    "            'total_drug_mentions': len(all_drugs),\n",
    "            'most_common_drugs': pd.Series(all_drugs).value_counts().head(10).to_dict()\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "\n",
    "# Initialize dataset creator\n",
    "dataset_creator = PrescriptionDatasetCreator(config.IMAGES_DIR, config.ANNOTATIONS_FILE)\n",
    "print(\"Dataset creator initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e97f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and prepare your dataset\n",
    "print(\"=== Dataset Preparation ===\")\n",
    "\n",
    "# Check if images directory has files\n",
    "image_files = list(config.IMAGES_DIR.glob('*.jpg')) + list(config.IMAGES_DIR.glob('*.png')) + list(config.IMAGES_DIR.glob('*.jpeg'))\n",
    "print(f\"Found {len(image_files)} image files in {config.IMAGES_DIR}\")\n",
    "\n",
    "if len(image_files) == 0:\n",
    "    print(\"\\nâš ï¸  No images found! Please:\")\n",
    "    print(f\"1. Add your prescription images to: {config.IMAGES_DIR}\")\n",
    "    print(\"2. Supported formats: .jpg, .png, .jpeg\")\n",
    "    print(\"3. Run this cell again after adding images\")\n",
    "else:\n",
    "    print(f\"âœ“ Images found: {[f.name for f in image_files[:5]]}...\")\n",
    "    \n",
    "    # Validate or create annotations\n",
    "    if dataset_creator.validate_dataset():\n",
    "        stats = dataset_creator.get_dataset_stats()\n",
    "        print(\"\\n=== Dataset Statistics ===\")\n",
    "        for key, value in stats.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸  Dataset validation failed or annotations not found!\")\n",
    "        print(\"Creating sample annotations structure...\")\n",
    "        dataset_creator.create_sample_annotations()\n",
    "        print(\"\\nPlease:\")\n",
    "        print(f\"1. Edit the annotations file: {config.ANNOTATIONS_FILE}\")\n",
    "        print(\"2. Add transcriptions for all your prescription images\")\n",
    "        print(\"3. Run this cell again after creating proper annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e004432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and initialize the TrOCR model\n",
    "print(\"=== Loading TrOCR Model ===\")\n",
    "\n",
    "# Load processor and model\n",
    "processor = TrOCRProcessor.from_pretrained(config.MODEL_NAME)\n",
    "model = VisionEncoderDecoderModel.from_pretrained(config.MODEL_NAME)\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "print(f\"âœ“ Loaded model: {config.MODEL_NAME}\")\n",
    "print(f\"âœ“ Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"âœ“ Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# Model configuration\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "\n",
    "# Set generation parameters for better prescription text generation\n",
    "model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
    "model.config.max_length = config.MAX_TARGET_LENGTH\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 4\n",
    "\n",
    "print(\"âœ“ Model configuration updated for prescription text generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4823cd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class for prescription images\n",
    "class PrescriptionOCRDataset:\n",
    "    \"\"\"Custom dataset class for prescription OCR\"\"\"\n",
    "    \n",
    "    def __init__(self, annotations: List[Dict], images_dir: Path, processor, max_target_length: int = 256):\n",
    "        self.annotations = annotations\n",
    "        self.images_dir = images_dir\n",
    "        self.processor = processor\n",
    "        self.max_target_length = max_target_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        annotation = self.annotations[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image_path = self.images_dir / annotation['image_id']\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # Process image\n",
    "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values.squeeze()\n",
    "        \n",
    "        # Process text\n",
    "        text = annotation['text']\n",
    "        labels = self.processor.tokenizer(\n",
    "            text, \n",
    "            padding=\"max_length\", \n",
    "            max_length=self.max_target_length, \n",
    "            truncation=True, \n",
    "            return_tensors=\"pt\"\n",
    "        ).input_ids.squeeze()\n",
    "        \n",
    "        # Replace padding token id with -100 for loss computation\n",
    "        labels[labels == self.processor.tokenizer.pad_token_id] = -100\n",
    "        \n",
    "        return {\n",
    "            'pixel_values': pixel_values,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "def create_datasets(annotations_data: Dict, images_dir: Path, processor, config: TrOCRConfig):\n",
    "    \"\"\"Create train/val/test datasets\"\"\"\n",
    "    annotations = annotations_data['annotations']\n",
    "    \n",
    "    # Split the data\n",
    "    np.random.shuffle(annotations)\n",
    "    \n",
    "    n_total = len(annotations)\n",
    "    n_train = int(n_total * config.TRAIN_SPLIT)\n",
    "    n_val = int(n_total * config.VAL_SPLIT)\n",
    "    \n",
    "    train_annotations = annotations[:n_train]\n",
    "    val_annotations = annotations[n_train:n_train + n_val]\n",
    "    test_annotations = annotations[n_train + n_val:]\n",
    "    \n",
    "    print(f\"Dataset split: Train={len(train_annotations)}, Val={len(val_annotations)}, Test={len(test_annotations)}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = PrescriptionOCRDataset(train_annotations, images_dir, processor, config.MAX_TARGET_LENGTH)\n",
    "    val_dataset = PrescriptionOCRDataset(val_annotations, images_dir, processor, config.MAX_TARGET_LENGTH)\n",
    "    test_dataset = PrescriptionOCRDataset(test_annotations, images_dir, processor, config.MAX_TARGET_LENGTH)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "print(\"Custom dataset classes defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d009d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets for training (only if annotations are available)\n",
    "annotations_data = dataset_creator.load_annotations()\n",
    "\n",
    "if annotations_data and len(annotations_data['annotations']) > 0:\n",
    "    print(\"=== Preparing Training Datasets ===\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset, val_dataset, test_dataset = create_datasets(\n",
    "        annotations_data, config.IMAGES_DIR, processor, config\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Training dataset: {len(train_dataset)} samples\")\n",
    "    print(f\"âœ“ Validation dataset: {len(val_dataset)} samples\")\n",
    "    print(f\"âœ“ Test dataset: {len(test_dataset)} samples\")\n",
    "    \n",
    "    # Test data loading\n",
    "    if len(train_dataset) > 0:\n",
    "        sample = train_dataset[0]\n",
    "        print(f\"\\nSample data shapes:\")\n",
    "        print(f\"Image (pixel_values): {sample['pixel_values'].shape}\")\n",
    "        print(f\"Labels: {sample['labels'].shape}\")\n",
    "        \n",
    "        # Decode sample text\n",
    "        sample_text = processor.tokenizer.decode(sample['labels'], skip_special_tokens=True)\n",
    "        print(f\"Sample text: '{sample_text[:100]}...'\")\n",
    "    \n",
    "    datasets_ready = True\n",
    "else:\n",
    "    print(\"âŒ No valid annotations found. Cannot proceed with training.\")\n",
    "    print(\"Please ensure you have:\")\n",
    "    print(\"1. Added prescription images to the images directory\")\n",
    "    print(\"2. Created proper annotations with transcribed text\")\n",
    "    datasets_ready = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153eb76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute evaluation metrics for OCR task\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # Decode predictions and labels\n",
    "    decoded_preds = processor.tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in labels as they are used for padding\n",
    "    labels = np.where(labels != -100, labels, processor.tokenizer.pad_token_id)\n",
    "    decoded_labels = processor.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Compute character-level accuracy\n",
    "    char_accuracy = []\n",
    "    word_accuracy = []\n",
    "    \n",
    "    for pred, label in zip(decoded_preds, decoded_labels):\n",
    "        # Character-level accuracy\n",
    "        if len(label) > 0:\n",
    "            char_acc = sum(c1 == c2 for c1, c2 in zip(pred, label)) / max(len(pred), len(label))\n",
    "            char_accuracy.append(char_acc)\n",
    "        \n",
    "        # Word-level accuracy\n",
    "        pred_words = set(pred.lower().split())\n",
    "        label_words = set(label.lower().split())\n",
    "        if len(label_words) > 0:\n",
    "            word_acc = len(pred_words & label_words) / len(label_words)\n",
    "            word_accuracy.append(word_acc)\n",
    "    \n",
    "    return {\n",
    "        'char_accuracy': np.mean(char_accuracy) if char_accuracy else 0.0,\n",
    "        'word_accuracy': np.mean(word_accuracy) if word_accuracy else 0.0,\n",
    "    }\n",
    "\n",
    "# Custom trainer for better logging\n",
    "class PrescriptionOCRTrainer(Trainer):\n",
    "    def log(self, logs):\n",
    "        if hasattr(self, '_log_history'):\n",
    "            self._log_history.append(logs)\n",
    "        else:\n",
    "            self._log_history = [logs]\n",
    "        super().log(logs)\n",
    "\n",
    "print(\"Evaluation metrics and custom trainer defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72888f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup and execution\n",
    "if datasets_ready:\n",
    "    print(\"=== Setting Up Training ===\")\n",
    "    \n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=str(config.OUTPUT_DIR),\n",
    "        per_device_train_batch_size=config.BATCH_SIZE,\n",
    "        per_device_eval_batch_size=config.BATCH_SIZE,\n",
    "        num_train_epochs=config.NUM_EPOCHS,\n",
    "        learning_rate=config.LEARNING_RATE,\n",
    "        warmup_steps=config.WARMUP_STEPS,\n",
    "        logging_steps=10,\n",
    "        eval_steps=config.EVAL_STEPS,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_steps=config.SAVE_STEPS,\n",
    "        save_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"char_accuracy\",\n",
    "        greater_is_better=True,\n",
    "        remove_unused_columns=False,\n",
    "        dataloader_pin_memory=False,\n",
    "        fp16=torch.cuda.is_available(),  # Use mixed precision if GPU available\n",
    "        report_to=\"none\",  # Disable wandb/tensorboard for simplicity\n",
    "        seed=42,\n",
    "    )\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = PrescriptionOCRTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=default_data_collator,\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Trainer initialized with {len(train_dataset)} training samples\")\n",
    "    print(f\"âœ“ GPU memory usage: {torch.cuda.memory_allocated() / 1024**3:.1f} GB\" if torch.cuda.is_available() else \"âœ“ Using CPU\")\n",
    "    \n",
    "    # Start training\n",
    "    print(\"\\nðŸš€ Starting training...\")\n",
    "    print(f\"Training for {config.NUM_EPOCHS} epochs with batch size {config.BATCH_SIZE}\")\n",
    "    \n",
    "    try:\n",
    "        trainer.train()\n",
    "        print(\"\\nâœ… Training completed successfully!\")\n",
    "        \n",
    "        # Save the final model\n",
    "        trainer.save_model()\n",
    "        processor.save_pretrained(config.OUTPUT_DIR)\n",
    "        \n",
    "        print(f\"âœ“ Model saved to: {config.OUTPUT_DIR}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Training failed: {str(e)}\")\n",
    "        print(\"This might be due to:\")\n",
    "        print(\"- Insufficient GPU memory (try reducing batch size)\")\n",
    "        print(\"- Corrupted images in the dataset\")\n",
    "        print(\"- Invalid annotations format\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ Cannot start training - datasets not ready\")\n",
    "    print(\"Please complete the dataset preparation steps first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c777bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation and testing\n",
    "if datasets_ready and len(test_dataset) > 0:\n",
    "    print(\"=== Evaluating Fine-tuned Model ===\")\n",
    "    \n",
    "    # Load the best model if training was successful\n",
    "    try:\n",
    "        model_path = config.OUTPUT_DIR\n",
    "        if (model_path / \"pytorch_model.bin\").exists():\n",
    "            print(\"Loading fine-tuned model...\")\n",
    "            fine_tuned_model = VisionEncoderDecoderModel.from_pretrained(model_path)\n",
    "            fine_tuned_processor = TrOCRProcessor.from_pretrained(model_path)\n",
    "            fine_tuned_model.to(device)\n",
    "        else:\n",
    "            print(\"Using current model (training may not have completed)\")\n",
    "            fine_tuned_model = model\n",
    "            fine_tuned_processor = processor\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        fine_tuned_model.eval()\n",
    "        test_predictions = []\n",
    "        test_ground_truth = []\n",
    "        \n",
    "        print(f\"Testing on {len(test_dataset)} samples...\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(len(test_dataset)), desc=\"Evaluating\"):\n",
    "                sample = test_dataset[i]\n",
    "                \n",
    "                # Get prediction\n",
    "                pixel_values = sample['pixel_values'].unsqueeze(0).to(device)\n",
    "                generated_ids = fine_tuned_model.generate(pixel_values, max_length=config.MAX_TARGET_LENGTH)\n",
    "                generated_text = fine_tuned_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "                \n",
    "                # Get ground truth\n",
    "                labels = sample['labels']\n",
    "                labels = labels[labels != -100]  # Remove padding\n",
    "                ground_truth = fine_tuned_processor.tokenizer.decode(labels, skip_special_tokens=True)\n",
    "                \n",
    "                test_predictions.append(generated_text)\n",
    "                test_ground_truth.append(ground_truth)\n",
    "        \n",
    "        # Calculate overall metrics\n",
    "        char_accuracies = []\n",
    "        word_accuracies = []\n",
    "        exact_matches = 0\n",
    "        \n",
    "        for pred, truth in zip(test_predictions, test_ground_truth):\n",
    "            # Character accuracy\n",
    "            if len(truth) > 0:\n",
    "                char_acc = sum(c1 == c2 for c1, c2 in zip(pred, truth)) / max(len(pred), len(truth))\n",
    "                char_accuracies.append(char_acc)\n",
    "            \n",
    "            # Word accuracy\n",
    "            pred_words = set(pred.lower().split())\n",
    "            truth_words = set(truth.lower().split())\n",
    "            if len(truth_words) > 0:\n",
    "                word_acc = len(pred_words & truth_words) / len(truth_words)\n",
    "                word_accuracies.append(word_acc)\n",
    "            \n",
    "            # Exact match\n",
    "            if pred.strip().lower() == truth.strip().lower():\n",
    "                exact_matches += 1\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\n=== Test Results ===\")\n",
    "        print(f\"Character Accuracy: {np.mean(char_accuracies):.3f} Â± {np.std(char_accuracies):.3f}\")\n",
    "        print(f\"Word Accuracy: {np.mean(word_accuracies):.3f} Â± {np.std(word_accuracies):.3f}\")\n",
    "        print(f\"Exact Match Accuracy: {exact_matches / len(test_predictions):.3f} ({exact_matches}/{len(test_predictions)})\")\n",
    "        \n",
    "        # Show sample predictions\n",
    "        print(\"\\n=== Sample Predictions ===\")\n",
    "        for i in range(min(3, len(test_predictions))):\n",
    "            print(f\"\\nSample {i+1}:\")\n",
    "            print(f\"Ground Truth: {test_ground_truth[i][:100]}...\")\n",
    "            print(f\"Prediction:   {test_predictions[i][:100]}...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Evaluation failed: {str(e)}\")\n",
    "else:\n",
    "    print(\"âŒ Cannot evaluate - no test dataset available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31d2194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drug extraction utility for Zaura Health integration\n",
    "class PrescriptionDrugExtractor:\n",
    "    \"\"\"Extract structured drug information from OCR text for Zaura Health\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Common drug name patterns\n",
    "        self.drug_patterns = [\n",
    "            r'([A-Za-z][A-Za-z0-9]+)\\s+(\\d+(?:\\.\\d+)?\\s*(?:mg|g|ml|mcg|units?))',\n",
    "            r'([A-Za-z][A-Za-z0-9]+)\\s+([0-9\\.]+)\\s*(mg|g|ml|mcg|units?)',\n",
    "        ]\n",
    "        \n",
    "        # Frequency patterns\n",
    "        self.frequency_patterns = [\n",
    "            r'(once|twice|three times|four times)\\s+(daily|per day)',\n",
    "            r'(\\d+)\\s*times?\\s+(daily|per day|a day)',\n",
    "            r'every\\s+(\\d+)\\s*hours?',\n",
    "            r'as needed',\n",
    "            r'PRN'\n",
    "        ]\n",
    "    \n",
    "    def extract_medications(self, ocr_text: str) -> Dict:\n",
    "        \"\"\"Extract structured medication information from OCR text\"\"\"\n",
    "        medications = []\n",
    "        \n",
    "        # Split text into lines\n",
    "        lines = ocr_text.strip().split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            # Extract drug name and dosage\n",
    "            drug_match = None\n",
    "            for pattern in self.drug_patterns:\n",
    "                match = re.search(pattern, line, re.IGNORECASE)\n",
    "                if match:\n",
    "                    drug_match = match\n",
    "                    break\n",
    "            \n",
    "            if drug_match:\n",
    "                drug_name = drug_match.group(1)\n",
    "                dosage = drug_match.group(2)\n",
    "                \n",
    "                # Extract frequency\n",
    "                frequency = \"as needed\"  # default\n",
    "                for freq_pattern in self.frequency_patterns:\n",
    "                    freq_match = re.search(freq_pattern, line, re.IGNORECASE)\n",
    "                    if freq_match:\n",
    "                        frequency = freq_match.group(0)\n",
    "                        break\n",
    "                \n",
    "                medications.append({\n",
    "                    'drug_name': drug_name,\n",
    "                    'dosage': dosage,\n",
    "                    'frequency': frequency,\n",
    "                    'raw_text': line\n",
    "                })\n",
    "        \n",
    "        return {\n",
    "            'medications': medications,\n",
    "            'total_medications': len(medications),\n",
    "            'raw_ocr_text': ocr_text\n",
    "        }\n",
    "    \n",
    "    def format_for_zaura_health(self, extracted_data: Dict) -> Dict:\n",
    "        \"\"\"Format extracted data for Zaura Health drug interaction model\"\"\"\n",
    "        drugs = [med['drug_name'] for med in extracted_data['medications']]\n",
    "        \n",
    "        # Calculate total daily doses (simplified)\n",
    "        total_doses = 0\n",
    "        for med in extracted_data['medications']:\n",
    "            freq_text = med['frequency'].lower()\n",
    "            if 'once' in freq_text:\n",
    "                total_doses += 1\n",
    "            elif 'twice' in freq_text:\n",
    "                total_doses += 2\n",
    "            elif 'three' in freq_text:\n",
    "                total_doses += 3\n",
    "            else:\n",
    "                total_doses += 1  # default\n",
    "        \n",
    "        zaura_format = {\n",
    "            'drugs': drugs[:10],  # Limit to 10 drugs (model constraint)\n",
    "            'total_drugs': len(drugs),\n",
    "            'doses_per_24_hrs': total_doses,\n",
    "            'has_dosage_info': 1 if any('mg' in med['dosage'] for med in extracted_data['medications']) else 0,\n",
    "            'extracted_medications': extracted_data['medications']\n",
    "        }\n",
    "        \n",
    "        return zaura_format\n",
    "\n",
    "# Initialize drug extractor\n",
    "drug_extractor = PrescriptionDrugExtractor()\n",
    "print(\"Drug extraction utility ready for Zaura Health integration!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fba2a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete pipeline: Image â†’ OCR â†’ Drug Extraction â†’ Zaura Health Format\n",
    "def process_prescription_image(image_path: str, model, processor) -> Dict:\n",
    "    \"\"\"Complete pipeline to process a prescription image\"\"\"\n",
    "    try:\n",
    "        # Load and preprocess image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # OCR with fine-tuned model\n",
    "        pixel_values = processor(image, return_tensors=\"pt\").pixel_values.to(device)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(\n",
    "                pixel_values,\n",
    "                max_length=config.MAX_TARGET_LENGTH,\n",
    "                num_beams=4,\n",
    "                early_stopping=True\n",
    "            )\n",
    "        \n",
    "        ocr_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        # Extract drug information\n",
    "        extracted_data = drug_extractor.extract_medications(ocr_text)\n",
    "        \n",
    "        # Format for Zaura Health\n",
    "        zaura_format = drug_extractor.format_for_zaura_health(extracted_data)\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'ocr_text': ocr_text,\n",
    "            'extracted_medications': extracted_data,\n",
    "            'zaura_health_format': zaura_format\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "# Test the complete pipeline if we have a trained model\n",
    "if datasets_ready and (config.OUTPUT_DIR / \"pytorch_model.bin\").exists():\n",
    "    print(\"=== Testing Complete Pipeline ===\")\n",
    "    \n",
    "    # Load fine-tuned model\n",
    "    test_model = VisionEncoderDecoderModel.from_pretrained(config.OUTPUT_DIR)\n",
    "    test_processor = TrOCRProcessor.from_pretrained(config.OUTPUT_DIR)\n",
    "    test_model.to(device)\n",
    "    \n",
    "    # Test with a sample image\n",
    "    sample_images = list(config.IMAGES_DIR.glob('*.jpg'))[:3]  # Test first 3 images\n",
    "    \n",
    "    for i, img_path in enumerate(sample_images):\n",
    "        print(f\"\\n--- Processing {img_path.name} ---\")\n",
    "        result = process_prescription_image(str(img_path), test_model, test_processor)\n",
    "        \n",
    "        if result['success']:\n",
    "            print(f\"OCR Text: {result['ocr_text'][:100]}...\")\n",
    "            print(f\"Extracted Drugs: {[med['drug_name'] for med in result['extracted_medications']['medications']]}\")\n",
    "            print(f\"Zaura Health Format: {result['zaura_health_format']['drugs']}\")\n",
    "        else:\n",
    "            print(f\"Error: {result['error']}\")\n",
    "\n",
    "else:\n",
    "    print(\"Complete pipeline test skipped - model not trained yet\")\n",
    "    print(\"The pipeline function is ready for use after training completion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69fe2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create API endpoint for Zaura Health website integration\n",
    "api_code = '''\n",
    "# Save this as prescription_ocr_api.py\n",
    "from flask import Flask, request, jsonify\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "import io\n",
    "import base64\n",
    "import re\n",
    "from typing import Dict\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load model once when server starts\n",
    "MODEL_PATH = \"./trocr_prescription_model\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "try:\n",
    "    processor = TrOCRProcessor.from_pretrained(MODEL_PATH)\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(MODEL_PATH)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded successfully on {device}\")\n",
    "except:\n",
    "    # Fallback to base model if fine-tuned model not available\n",
    "    processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(\"Using base TrOCR model (fine-tuned model not found)\")\n",
    "\n",
    "class DrugExtractor:\n",
    "    def __init__(self):\n",
    "        self.drug_patterns = [\n",
    "            r'([A-Za-z][A-Za-z0-9]+)\\\\s+(\\\\d+(?:\\\\.\\\\d+)?\\\\s*(?:mg|g|ml|mcg|units?))',\n",
    "            r'([A-Za-z][A-Za-z0-9]+)\\\\s+([0-9\\\\.]+)\\\\s*(mg|g|ml|mcg|units?)'\n",
    "        ]\n",
    "    \n",
    "    def extract_medications(self, ocr_text: str) -> Dict:\n",
    "        medications = []\n",
    "        lines = ocr_text.strip().split('\\\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            for pattern in self.drug_patterns:\n",
    "                match = re.search(pattern, line, re.IGNORECASE)\n",
    "                if match:\n",
    "                    medications.append({\n",
    "                        'drug_name': match.group(1),\n",
    "                        'dosage': match.group(2) if len(match.groups()) > 1 else '',\n",
    "                        'raw_text': line\n",
    "                    })\n",
    "                    break\n",
    "        \n",
    "        return medications\n",
    "\n",
    "drug_extractor = DrugExtractor()\n",
    "\n",
    "@app.route('/ocr', methods=['POST'])\n",
    "def process_prescription():\n",
    "    try:\n",
    "        # Get image from request\n",
    "        if 'image' not in request.files:\n",
    "            return jsonify({'error': 'No image provided'}), 400\n",
    "        \n",
    "        image_file = request.files['image']\n",
    "        image = Image.open(image_file.stream).convert('RGB')\n",
    "        \n",
    "        # Process with TrOCR\n",
    "        pixel_values = processor(image, return_tensors=\"pt\").pixel_values.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(pixel_values, max_length=256)\n",
    "        \n",
    "        ocr_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        # Extract medications\n",
    "        medications = drug_extractor.extract_medications(ocr_text)\n",
    "        drug_names = [med['drug_name'] for med in medications]\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'ocr_text': ocr_text,\n",
    "            'drugs': drug_names[:10],  # Limit to 10 for Zaura Health model\n",
    "            'total_drugs': len(drug_names),\n",
    "            'medications': medications\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health_check():\n",
    "    return jsonify({'status': 'healthy', 'model_loaded': True})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000, debug=True)\n",
    "'''\n",
    "\n",
    "# Save API code to file\n",
    "with open('prescription_ocr_api.py', 'w') as f:\n",
    "    f.write(api_code)\n",
    "\n",
    "print(\"\\n=== API Integration Code Generated ===\")\n",
    "print(\"âœ“ Flask API saved as: prescription_ocr_api.py\")\n",
    "print(\"\\nTo use with Zaura Health:\")\n",
    "print(\"1. Run: python prescription_ocr_api.py\")\n",
    "print(\"2. API will be available at: http://localhost:5000\")\n",
    "print(\"3. POST prescription images to: /ocr\")\n",
    "print(\"4. Health check at: /health\")\n",
    "\n",
    "# Integration example for Zaura Health frontend\n",
    "integration_js = '''\n",
    "// JavaScript for Zaura Health website integration\n",
    "async function uploadPrescription(imageFile) {\n",
    "    const formData = new FormData();\n",
    "    formData.append('image', imageFile);\n",
    "    \n",
    "    try {\n",
    "        const response = await fetch('http://localhost:5000/ocr', {\n",
    "            method: 'POST',\n",
    "            body: formData\n",
    "        });\n",
    "        \n",
    "        const result = await response.json();\n",
    "        \n",
    "        if (result.success) {\n",
    "            // Populate drug input fields with extracted data\n",
    "            populateDrugFields(result.drugs);\n",
    "            showOCRResult(result.ocr_text);\n",
    "        } else {\n",
    "            showError(result.error);\n",
    "        }\n",
    "    } catch (error) {\n",
    "        showError('Failed to process prescription: ' + error.message);\n",
    "    }\n",
    "}\n",
    "\n",
    "function populateDrugFields(drugs) {\n",
    "    // Fill the drug input fields in Zaura Health form\n",
    "    for (let i = 0; i < Math.min(drugs.length, 10); i++) {\n",
    "        const drugInput = document.getElementById(`drug${i+1}`);\n",
    "        if (drugInput) {\n",
    "            drugInput.value = drugs[i];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "'''\n",
    "\n",
    "with open('zaura_health_integration.js', 'w') as f:\n",
    "    f.write(integration_js)\n",
    "\n",
    "print(\"\\nâœ“ JavaScript integration saved as: zaura_health_integration.js\")\n",
    "print(\"\\n=== Complete Integration Ready! ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e00975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and next steps\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TROCR PRESCRIPTION OCR - SETUP COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ“ DIRECTORY STRUCTURE:\")\n",
    "print(f\"â”œâ”€â”€ {config.DATA_DIR}/\")\n",
    "print(f\"â”‚   â”œâ”€â”€ images/          # Your prescription images\")\n",
    "print(f\"â”‚   â””â”€â”€ annotations.json # Ground truth transcriptions\")\n",
    "print(f\"â”œâ”€â”€ {config.OUTPUT_DIR}/ # Fine-tuned model\")\n",
    "print(\"â”œâ”€â”€ prescription_ocr_api.py      # Flask API\")\n",
    "â””â”€â”€ zaura_health_integration.js  # Frontend integration\")\n",
    "\n",
    "print(\"\\nðŸš€ NEXT STEPS:\")\n",
    "print(\"\\n1. PREPARE YOUR DATA:\")\n",
    "print(f\"   â€¢ Add prescription images to: {config.IMAGES_DIR}\")\n",
    "print(f\"   â€¢ Create transcriptions in: {config.ANNOTATIONS_FILE}\")\n",
    "\n",
    "print(\"\\n2. FINE-TUNE THE MODEL:\")\n",
    "print(\"   â€¢ Run all cells in this notebook\")\n",
    "print(\"   â€¢ Monitor training progress and metrics\")\n",
    "print(\"   â€¢ Adjust hyperparameters if needed\")\n",
    "\n",
    "print(\"\\n3. DEPLOY TO ZAURA HEALTH:\")\n",
    "print(\"   â€¢ Run: python prescription_ocr_api.py\")\n",
    "print(\"   â€¢ Integrate with Zaura Health frontend\")\n",
    "print(\"   â€¢ Test end-to-end pipeline\")\n",
    "\n",
    "print(\"\\nðŸ“Š EXPECTED PERFORMANCE:\")\n",
    "print(\"â€¢ Character accuracy: 85-95% (depending on image quality)\")\n",
    "print(\"â€¢ Word accuracy: 80-90% (for medical terms)\")\n",
    "print(\"â€¢ Processing time: ~1-3 seconds per image\")\n",
    "\n",
    "print(\"\\nâš¡ OPTIMIZATION TIPS:\")\n",
    "print(\"â€¢ Use high-quality, well-lit prescription images\")\n",
    "print(\"â€¢ Ensure handwriting is legible in training data\")\n",
    "print(\"â€¢ Add domain-specific medical terms to training\")\n",
    "print(\"â€¢ Use GPU for faster training and inference\")\n",
    "\n",
    "print(\"\\nâœ… Ready to process handwritten prescriptions for Zaura Health!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
