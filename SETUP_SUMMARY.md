# Setup Complete - What You Need to Know

## üéØ What Was Created

This PR adds comprehensive setup documentation for your Drug Interaction Prediction project, specifically addressing PySpark and Java compatibility issues.

### New Files:

1. **`important.txt`** - The main reference document
   - Complete installation guide
   - Version compatibility matrix
   - Troubleshooting section
   - 11 comprehensive sections covering all aspects

2. **`QUICK_SETUP_GUIDE.md`** - Fast setup for getting started
   - TL;DR commands to get up and running
   - Quick verification steps
   - Common issues and fixes

3. **`SPARKNOTE_CONFIG_GUIDE.md`** - Notebook configuration guide
   - How to switch between HDFS and local files
   - Step-by-step configuration instructions
   - Examples for different operating systems

### Modified Files:

1. **`CombineDatasets.scala`** - Now supports both HDFS and local files
   - Added `USE_HDFS` configuration flag
   - Easy toggle between HDFS and local file system
   - Clear comments for customization

## üö® Critical Issue Identified and Solved

### The Problem:
**Java 10 is NOT compatible with PySpark!**

You mentioned using Java 10, but PySpark requires:
- ‚úÖ Java 8
- ‚úÖ Java 11 (RECOMMENDED)
- ‚úÖ Java 17
- ‚ùå Java 10 (NOT SUPPORTED)

### The Solution:
Install Java 11 in your `torch_new` conda environment:
```bash
conda activate torch_new
conda install -c conda-forge openjdk=11
```

## üöÄ Quick Start (3 Minutes)

```bash
# 1. Activate your environment
conda activate torch_new

# 2. Install Java 11 (CRITICAL!)
conda install -c conda-forge openjdk=11 -y

# 3. Install PySpark
conda install -c conda-forge pyspark=3.3.2 -y

# 4. Install PyTorch (choose GPU or CPU)
conda install pytorch==2.0.1 torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y

# 5. Install ML libraries
conda install scikit-learn pandas numpy matplotlib seaborn -y
pip install xgboost==1.7.6

# 6. Install Jupyter
conda install jupyter notebook -y

# 7. Verify
java -version  # Should show 11.x
python -c "import pyspark; print(pyspark.__version__)"
python -c "import torch; print(torch.__version__)"
```

## üìö Which Document to Read When

### Just Getting Started?
‚Üí Read **`QUICK_SETUP_GUIDE.md`**
- Quick commands to get running
- 5 minutes to complete

### Need Full Details?
‚Üí Read **`important.txt`**
- Complete reference
- All versions and compatibility info
- Troubleshooting guide

### Want to Skip HDFS Setup?
‚Üí Read **`SPARKNOTE_CONFIG_GUIDE.md`**
- How to use local files instead of HDFS
- Step-by-step configuration
- Much simpler for testing

### Ready to Run Code?
‚Üí Check updated **`CombineDatasets.scala`**
- Look for `USE_HDFS` flag at line 10
- Set to `false` to use local files
- Update file paths as needed

## üéì What Each File Does

### Your Project Has 3 Main Components:

1. **`CombineDatasets.scala`** (Scala + Spark)
   - Preprocesses and combines datasets
   - **Requires:** Java 11, Scala 2.12.15, Spark 3.3.2
   - **Optional:** HDFS (or use local files)
   - **Run First:** This creates the dataset for other notebooks

2. **`sparknote.ipynb`** (PySpark MLlib)
   - Machine learning with distributed Spark
   - **Requires:** Java 11, PySpark 3.3.2
   - **Models:** Logistic Regression, Random Forest, GBT
   - **Optional:** HDFS (or use local files)

3. **`multi_model_drug_interaction_prediction.ipynb`** (PyTorch/XGBoost)
   - Advanced ML with neural networks
   - **Requires:** PyTorch 2.0.1, XGBoost 1.7.6
   - **Models:** Random Forest, XGBoost, PyTorch NN
   - **Optional:** CUDA for GPU acceleration

## ‚öôÔ∏è Two Setup Options

### Option A: Full Setup (HDFS + Spark + PyTorch)
**Best for:** Production, large datasets, distributed processing

**Time:** ~1 hour to set up
**Complexity:** High
**Performance:** Excellent for large data

Follow all instructions in `important.txt`

### Option B: Simple Setup (Local Files + PyTorch)
**Best for:** Learning, testing, development

**Time:** ~10 minutes to set up
**Complexity:** Low
**Performance:** Good for datasets < 1GB

1. Follow `QUICK_SETUP_GUIDE.md` (skip HDFS section)
2. Set `USE_HDFS = false` in `CombineDatasets.scala`
3. Update file paths to your local CSV files
4. Follow `SPARKNOTE_CONFIG_GUIDE.md` for notebook setup

## üîß Recommended Configuration for torch_new

Based on your setup (conda environment + Java 10 issue), here's what we recommend:

```bash
# Essential (MUST HAVE)
Java: 11.0.x                    # Your Java 10 won't work!
Python: 3.10                    # Already in torch_new
PySpark: 3.3.2                  # For Spark notebooks
PyTorch: 2.0.1 + CUDA 11.8      # For ML notebooks
scikit-learn: 1.3.0             # For ML notebooks
XGBoost: 1.7.6                  # For ML notebooks

# Optional (NICE TO HAVE)
Scala: 2.12.15                  # For running .scala files
SBT: 1.8.x                      # For building Scala projects
Hadoop/HDFS: 3.3.4              # For distributed storage
```

## üéØ Installation Priority

**Phase 1: Critical (Do This First)**
1. ‚úÖ Install Java 11
2. ‚úÖ Verify Java version
3. ‚úÖ Install PySpark
4. ‚úÖ Test PySpark works

**Phase 2: Machine Learning**
5. ‚úÖ Install PyTorch (GPU or CPU)
6. ‚úÖ Install XGBoost
7. ‚úÖ Install scikit-learn, pandas, numpy
8. ‚úÖ Install visualization libraries

**Phase 3: Optional Advanced Features**
9. ‚¨ú Install Scala and SBT (if running .scala files)
10. ‚¨ú Install and configure HDFS (if using distributed storage)

## ‚úÖ Verification Checklist

Run these commands to verify everything is working:

```bash
# Check Java (MUST be 11.x)
java -version

# Check Python
python --version

# Check PySpark
python -c "import pyspark; print(f'‚úì PySpark: {pyspark.__version__}')"

# Check PyTorch
python -c "import torch; print(f'‚úì PyTorch: {torch.__version__}'); print(f'‚úì CUDA: {torch.cuda.is_available()}')"

# Check XGBoost
python -c "import xgboost; print(f'‚úì XGBoost: {xgboost.__version__}')"

# Check scikit-learn
python -c "import sklearn; print(f'‚úì scikit-learn: {sklearn.__version__}')"

# Test PySpark connection
python -c "from pyspark.sql import SparkSession; spark = SparkSession.builder.master('local').appName('test').getOrCreate(); print('‚úì Spark works!'); spark.stop()"
```

All checks should pass without errors!

## üêõ Common Issues and Quick Fixes

### Issue 1: "Unsupported class file major version"
```bash
# Your Java version is wrong
conda activate torch_new
conda install -c conda-forge openjdk=11
java -version  # Verify it's 11.x
```

### Issue 2: "Cannot import pyspark"
```bash
# PySpark not installed
conda activate torch_new
conda install -c conda-forge pyspark=3.3.2
```

### Issue 3: "Cannot connect to HDFS"
```bash
# Either start HDFS OR use local files
# Option 1: Start HDFS
start-dfs.sh

# Option 2: Use local files (easier)
# Edit CombineDatasets.scala: Set USE_HDFS = false
# See SPARKNOTE_CONFIG_GUIDE.md for notebook changes
```

### Issue 4: "JAVA_HOME not set"
```bash
# Set JAVA_HOME
export JAVA_HOME=$(dirname $(dirname $(readlink -f $(which java))))
# Make permanent by adding to ~/.bashrc
echo 'export JAVA_HOME=$(dirname $(dirname $(readlink -f $(which java))))' >> ~/.bashrc
```

## üìñ Next Steps

1. **Read the Quick Setup Guide**
   - File: `QUICK_SETUP_GUIDE.md`
   - Time: 5 minutes

2. **Install Required Software**
   - Follow commands from Quick Setup Guide
   - Verify with checklist above

3. **Decide: HDFS or Local Files?**
   - HDFS: Follow `important.txt` Section 3
   - Local: Follow `SPARKNOTE_CONFIG_GUIDE.md`

4. **Run the Notebooks**
   - Start with: `CombineDatasets.scala` (prepare data)
   - Then: `sparknote.ipynb` or `multi_model_drug_interaction_prediction.ipynb`

5. **Need Help?**
   - Check troubleshooting sections in documentation
   - Verify Java version (most common issue!)
   - Ensure conda environment is activated

## üìû Support Resources

- **Quick Setup:** See `QUICK_SETUP_GUIDE.md`
- **Full Reference:** See `important.txt`
- **Spark Config:** See `SPARKNOTE_CONFIG_GUIDE.md`
- **Troubleshooting:** All documents have dedicated sections

## üéâ You're All Set!

Follow the Quick Setup Guide, and you'll be running your first notebook in under 10 minutes.

The most important thing: **Install Java 11!** Everything else will fall into place.

Good luck! üöÄ
